{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "import requests\n",
    "import spotipy  # Note spotipy package must first be installed: go to terminal and type \"pip install spotipy\"\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_STRINGS = {\"featuring\", \"feat\", \"ft\", \"with\"}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get music charts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data shape:\n",
    "\n",
    "A $n\\times6$ dataframe where $n$ is the number of songs scraped.\n",
    "\n",
    "Columns include:  \n",
    "- `number`: where the song was positioned in the chart\n",
    "- `song`: the name of the song\n",
    "- `artist`: the name of the artist(s)\n",
    "- `chart_name`: the name of the chart it appeared in\n",
    "- `year`: the year it charted\n",
    "- `region`: the country the chart is from\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Billboard top 100 annual charts\n",
    "\n",
    "Access the US Billboards Chart data from Wikipedia and create a DataFrame of the Top 100 Songs for each year between 1980 to 2023."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A total of 1 years have been scraped successfully.                                                                      \n"
     ]
    }
   ],
   "source": [
    "startYear, endYear = 2020, 2020 # Reduced year range for working.\n",
    "fileOut = \"data/charts.json\"\n",
    "\n",
    "\n",
    "def scrape_billboard_wiki(\n",
    "        year,\n",
    "        url=\"https://en.wikipedia.org/wiki/Billboard_Year-End_Hot_100_singles_of_{}\",\n",
    "        chartName=\"Billboard Top 100\",\n",
    "        chartRegion=\"US\"\n",
    "        ):\n",
    "    \n",
    "    url = url.format(year)\n",
    "    print(f\"Scraping URL: {url}\", end=\"\\r\")\n",
    "\n",
    "    # Get tables from URL\n",
    "    wikitables = pd.read_html(url, attrs={'class': 'wikitable'},)\n",
    "\n",
    "    # Get first table on page\n",
    "    chart = wikitables[0]\n",
    "\n",
    "    # Fix inconsistent header name for chart position\n",
    "    chart = chart.rename(columns={\n",
    "        chart.columns[0]: 'number',\n",
    "        chart.columns[1]: 'song',\n",
    "        chart.columns[2]: 'artist'\n",
    "        })\n",
    "\n",
    "    # Remove quotation marks from song names\n",
    "    chart[\"song\"] = chart[\"song\"].apply(str.strip, args=('\"'))\n",
    "\n",
    "    # Add metadata to entries\n",
    "    chart[\"chart_name\"] = chartName\n",
    "    chart[\"year\"] = year\n",
    "    chart[\"region\"] = chartRegion\n",
    "\n",
    "    return chart\n",
    "\n",
    "\n",
    "# Create dataframe of charts\n",
    "billboard_charts = pd.concat([\n",
    "    scrape_billboard_wiki(year)\n",
    "    for year\n",
    "    in range(startYear, endYear+1)\n",
    "    ])\n",
    "\n",
    "print(f\"A total of {endYear - startYear + 1} years have been scraped successfully.\".ljust(120))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine all charts to one DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A total of 100 song objects have been created for years 2020-2020.                                                      \n"
     ]
    }
   ],
   "source": [
    "debugLimit = None\n",
    "\n",
    "# Combine all charts into one DataFrame\n",
    "charts = pd.concat([billboard_charts])\n",
    "if debugLimit: charts = charts.iloc[:debugLimit]\n",
    "\n",
    "print(f\"A total of {len(charts)} song objects have been created for years {startYear}-{endYear}.\".ljust(120))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Spotify ID for songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Spotify IDs for 100 of 100 songs (100.00% success)                                                                \n"
     ]
    }
   ],
   "source": [
    "waitBetweenQueries = 0.2\n",
    "credentialsPath = \"credentials.json\"\n",
    "\n",
    "# Load credentials from JSON file\n",
    "with open(credentialsPath, 'r') as fh:\n",
    "    credentials = json.load(fh)[0]\n",
    "\n",
    "# Spotify setup\n",
    "client_credentials_manager = SpotifyClientCredentials(**credentials)\n",
    "sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)\n",
    "\n",
    "\n",
    "def search_spotify(query, quiet=False):\n",
    "    \"\"\"\n",
    "    This function takes an input parameter of a search query; searches Spotify\n",
    "    and returns the Spotify ID for the track if found, else None.\n",
    "    \"\"\"\n",
    "\n",
    "    # see https://developer.spotify.com/documentation/web-api/reference/#category-search for information\n",
    "    # regarding using the Search API\n",
    "\n",
    "    search = sp.search(query, type=\"track\", limit=1)  # Assuming first song returned will be best match\n",
    "    song = search[\"tracks\"][\"items\"]\n",
    "\n",
    "    if not quiet: print(f\"\"\"{\"--- Result\" if song else \"*** No result\"} found for '{query}'\"\"\".ljust(120), end=\"\\r\")\n",
    "\n",
    "    time.sleep(waitBetweenQueries)\n",
    "\n",
    "    if song:\n",
    "        return song[0]\n",
    "    else:\n",
    "        # Try again without special characters\n",
    "        substring = re.sub(r\"[(){}[,.&/'\\]]\", \"\", query)\n",
    "        if substring != query: return search_spotify(substring, quiet)\n",
    "\n",
    "        # Try again without feature strings\n",
    "        substring = \" \".join([w for w in query.lower().split(\" \") if w not in FEATURE_STRINGS])\n",
    "        if substring != query: return search_spotify(substring, quiet)\n",
    "\n",
    "        # Give up if no matching song found\n",
    "        return None\n",
    "\n",
    "\n",
    "charts[\"id\"] = pd.Series(charts[\"song\"]+\" \"+charts[\"artist\"]).apply(search_spotify).apply(dict.get, args=(\"id\", None))\n",
    "\n",
    "print(f\"\"\"Found Spotify IDs for {charts[\"id\"].notna().sum()} of {len(charts)} songs ({charts[\"id\"].notna().sum()/len(charts)*100:.2f}% success)\"\"\".ljust(120))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Music Features for songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Music Features for 100 of 100 songs (100.00% success)                                                             \n"
     ]
    }
   ],
   "source": [
    "selectFeatures = {\n",
    "    \"danceability\",     \"acousticness\",\n",
    "    \"liveness\",         \"speechiness\",\n",
    "    \"instrumentalness\", \"energy\",\n",
    "    \"valence\",          \"tempo\",\n",
    "    \"duration_ms\"\n",
    "    }\n",
    "\n",
    "\n",
    "def get_music_feautures(id, features=selectFeatures, quiet=False):\n",
    "    result = sp.audio_features(id)[0]\n",
    "    if not quiet: print(f\"\"\"{\"--- Result\" if result else \"*** No result\"} found for '{id}'\"\"\".ljust(120), end=\"\\r\")\n",
    "    return {\n",
    "        k: v\n",
    "        for k, v\n",
    "        in result.items()\n",
    "        if k in features\n",
    "        }\n",
    "\n",
    "\n",
    "# Get a feature dictionary for each track\n",
    "charts[\"features\"] = charts[\"id\"].apply(get_music_feautures)\n",
    "\n",
    "# Expand feature dictionary keys to individual columns\n",
    "charts = pd.concat([charts, pd.DataFrame(charts[\"features\"].to_list())], axis=1)\n",
    "\n",
    "# Convert duration feature to seconds\n",
    "charts[\"duration\"] = charts[\"duration_ms\"]/1000\n",
    "charts.drop([\"duration_ms\", \"features\"], inplace=True, axis=1)\n",
    "\n",
    "print(f\"\"\"Found Music Features for {charts[\"duration\"].notna().sum()} of {len(charts)} songs ({charts[\"duration\"].notna().sum()/len(charts)*100:.2f}% success)\"\"\".ljust(120))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Lyrics for songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found lyrics for 61 of 100 songs (61.00% success)                                                                       \n"
     ]
    }
   ],
   "source": [
    "waitBetweenQueries = 0.5\n",
    "lyricsAPI = \"https://some-random-api.ml/lyrics?title={}\"\n",
    "\n",
    "\n",
    "def get_lyrics(query, quiet=False):\n",
    "    response = requests.get(lyricsAPI.format(query))\n",
    "    song = json.loads(response.text).get(\"lyrics\", None)\n",
    "    \n",
    "    if not quiet: print(f\"\"\"{\"--- Result\" if song else \"*** No result\"} found for '{query}'\"\"\".ljust(120), end=\"\\r\")\n",
    "    \n",
    "    time.sleep(waitBetweenQueries)\n",
    "\n",
    "    if song:\n",
    "        verses = song.split(\"\\n\\n\")\n",
    "        lyrics = [verse.split(\"\\n\") for verse in verses]\n",
    "        return lyrics\n",
    "    else:\n",
    "        # Try again without special characters\n",
    "        substring = re.sub(r\"[(){}[,.&/'\\]]\", \"\", query)\n",
    "        if substring != query: return get_lyrics(substring, quiet)\n",
    "\n",
    "        # Try again without feature strings\n",
    "        substring = \" \".join([w for w in query.lower().split(\" \") if w not in FEATURE_STRINGS])\n",
    "        if substring != query: return get_lyrics(substring, quiet)\n",
    "\n",
    "        # Give up if no matching song found\n",
    "        return None\n",
    "    \n",
    "\n",
    "charts[\"lyrics\"] = pd.Series(charts[\"song\"]+\" \"+charts[\"artist\"]).apply(get_lyrics)\n",
    "\n",
    "print(f\"\"\"Found lyrics for {charts[\"lyrics\"].notna().sum()} of {len(charts)} songs ({charts[\"lyrics\"].notna().sum()/len(charts)*100:.2f}% success)\"\"\".ljust(120))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write charts to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(fileOut, 'w') as fh:\n",
    "    charts.to_json(fh, orient=\"records\", indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bece7127777d8681f6b1909d19e009379ddeaa50e8dab6af7ea1715374cc99fb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
